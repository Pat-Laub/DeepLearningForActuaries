<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-15a8f4913ea29731a45b81ab225b8fd8.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-contrib/reveal-auto-agenda-0.0.3/reveal-auto-agenda.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.13">

  <meta name="author" content="Patrick Laub">
  <title>AI for Actuaries – Generative Adversarial Networks</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {  background-color: #e9ecef; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #0040ff; font-weight: bold; } /* Alert */
    code span.an { color: #4090c0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #336699; } /* Attribute */
    code span.bn { color: #0033a0; } /* BaseN */
    code span.bu { color: #0055cc; } /* BuiltIn */
    code span.cf { color: #0055cc; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #002080; } /* Constant */
    code span.co { color: #4090c0; font-style: italic; } /* Comment */
    code span.cv { color: #4090c0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #3060a0; font-style: italic; } /* Documentation */
    code span.dt { color: #0044bb; } /* DataType */
    code span.dv { color: #0033a0; } /* DecVal */
    code span.er { color: #0040ff; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #0033a0; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #0055cc; font-weight: bold; } /* Import */
    code span.in { color: #4090c0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #0055cc; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #0055cc; } /* Other */
    code span.pp { color: #336699; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #336699; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #4090c0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-0151b54ac4ccf28bedfd6d1098a60b77.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
<script>
  let selectedAnnoteEl;
</script>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Generative Adversarial Networks</h1>
  <p class="subtitle">ACTL3143 &amp; ACTL5111 Deep Learning for Actuaries</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Patrick Laub 
</div>
</div>
</div>

</section>
<section>
<section id="traditional-gans" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Traditional GANs</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-active">
<p>Traditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Training GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Conditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Image-to-image translation</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Problems with GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Wasserstein GAN</p>
</div></li>
</ul>
</div>
</section>
<section id="before-gans-we-had-autoencoders" class="slide level2">
<h2>Before GANs we had autoencoders</h2>
<p>An autoencoder takes a data/image, maps it to a latent space via en encoder module, then decodes it back to an output with the same dimensions via a decoder module.</p>

<img data-src="autoencoder.png" class="r-stretch quarto-figure-center"><p class="caption">Schematic of an autoencoder.</p><div class="footer">
<p>Source: Marcus Lautier (2022).</p>
</div>
</section>
<section id="gan-faces" class="slide level2">
<h2>GAN faces</h2>
<div class="columns">
<div class="column">
<p><img data-src="fakeface1.jpeg"></p>
</div><div class="column">
<p><img data-src="fakeface2.jpeg"></p>
</div></div>
<p>Try out <a href="https://www.whichfaceisreal.com">https://www.whichfaceisreal.com</a>.</p>
<div class="footer">
<p>Source: <a href="https://thispersondoesnotexist.com">https://thispersondoesnotexist.com</a>.</p>
</div>
</section>
<section id="example-stylegan2-ada-outputs" class="slide level2">
<h2>Example StyleGAN2-ADA outputs</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/kbDd5lW6rkM?start=171" width="800" height="500" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<div class="footer">
<p>Source: Jeff Heaton (2021), <a href="https://youtu.be/kbDd5lW6rkM">Training a GAN from your Own Images: StyleGAN2</a>.</p>
</div>
</section>
<section id="gan-structure" class="slide level2">
<h2>GAN structure</h2>

<img data-src="gan-diagram.png" class="r-stretch quarto-figure-center"><p class="caption">A schematic of a generative adversarial network.</p><div class="footer">
<p>Source: Thales Silva (2018), <a href="https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394">An intuitive introduction to Generative Adversarial Networks (GANs)</a>, freeCodeCamp.</p>
</div>
</section>
<section id="gan-intuition" class="slide level2">
<h2>GAN intuition</h2>
<p><img data-src="google-devs-bad_gan.svg"> <img data-src="google-devs-ok_gan.svg"> <img data-src="google-devs-good_gan.svg"></p>
<div class="footer">
<p>Source: Google Developers, <a href="https://developers.google.com/machine-learning/gan/gan_structure">Overview of GAN Structure</a>, Google Machine Learning Education.</p>
</div>
</section>
<section id="intuition-about-gans" class="slide level2 smaller">
<h2>Intuition about GANs</h2>
<ul>
<li>A forger creates a fake Picasso painting to sell to an art dealer.</li>
<li>The art dealer assesses the painting.</li>
</ul>
<p>How they best each other:</p>
<ul>
<li>The art dealer is given both authentic paintings and fake paintings to look at. Later on, the validity his assessment is evaluated and he trains to become better at detecting fakes. Over time, he becomes increasingly expert at authenticating Picasso’s artwork.</li>
<li>The forger receives an assessment from the art dealer everytime he gives him a fake. He knows he has to perfect his craft if the art dealer can detect his fake. He becomes increasingly adept at imitating Picasso’s style.</li>
</ul>
</section>
<section id="generative-adversarial-networks" class="slide level2">
<h2>Generative adversarial networks</h2>
<ul>
<li>A GAN is made up of two parts:
<ul>
<li>Generator network: the forger. Takes a random point in the latent space, and decodes it into a synthetic data/image.</li>
<li>Discriminator network (or adversary): the expert. Takes a data/image and decide whether it exists in the original data set (the training set) or was created by the generator network.</li>
</ul></li>
</ul>
</section>
<section id="discriminator" class="slide level2">
<h2>Discriminator</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a>lrelu <span class="op">=</span> layers.LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb1-2"><a></a></span>
<span id="cb1-3"><a></a>discriminator <span class="op">=</span> keras.Sequential([</span>
<span id="cb1-4"><a></a>    keras.Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)),</span>
<span id="cb1-5"><a></a>    layers.Conv2D(<span class="dv">64</span>, <span class="dv">3</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb1-6"><a></a>    layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb1-7"><a></a>    layers.GlobalMaxPooling2D(),</span>
<span id="cb1-8"><a></a>    layers.Dense(<span class="dv">1</span>)])</span>
<span id="cb1-9"><a></a></span>
<span id="cb1-10"><a></a>discriminator.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="generator" class="slide level2">
<h2>Generator</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>latent_dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb2-2"><a></a>generator <span class="op">=</span> keras.Sequential([</span>
<span id="cb2-3"><a></a>    layers.Dense(<span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">128</span>, input_dim<span class="op">=</span>latent_dim, activation<span class="op">=</span>lrelu),</span>
<span id="cb2-4"><a></a>    layers.Reshape((<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">128</span>)),</span>
<span id="cb2-5"><a></a>    layers.Conv2DTranspose(<span class="dv">128</span>, <span class="dv">4</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb2-6"><a></a>    layers.Conv2DTranspose(<span class="dv">128</span>, <span class="dv">4</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb2-7"><a></a>    layers.Conv2D(<span class="dv">1</span>, <span class="dv">7</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)])</span>
<span id="cb2-8"><a></a>generator.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section></section>
<section>
<section id="training-gans" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Training GANs</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Traditional GANs</p>
</div></li>
<li><div class="agenda-active">
<p>Training GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Conditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Image-to-image translation</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Problems with GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Wasserstein GAN</p>
</div></li>
</ul>
</div>
</section>
<section id="gan-cost-functions" class="slide level2">
<h2>GAN cost functions</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><video data-src="GANLoss.mp4" controls=""><a href="GANLoss.mp4">Video</a></video></p>
<figcaption>The loss function à la 3Blue1Brown.</figcaption>
</figure>
</div>
</section>
<section id="gan---schematic-process" class="slide level2">
<h2>GAN - Schematic process</h2>
<p>First step: Training <em>discriminator</em>:</p>
<ul>
<li>Draw random points in the latent space (random noise).</li>
<li>Use <em>generator</em> to generate data from this random noise.</li>
<li>Mix generated data with real data and input them into the <em>discriminator</em>. The training targets are the correct labels of <em>real data</em> or <em>fake data</em>. Use <em>discriminator</em> to give feedback on the mixed data whether they are real or synthetic. Train <em>discriminator</em> to minimize the loss function which is the difference between the <em>discriminator</em>’s feedback and the correct labels.</li>
</ul>
</section>
<section id="gan---schematic-process-ii" class="slide level2">
<h2>GAN - Schematic process II</h2>
<p>Second step: Training <em>generator</em>:</p>
<ul>
<li>Draw random points in the latent space and generate data with <em>generator</em>.</li>
<li>Use <em>discriminator</em> to give feedback on the generated data. What the generator tries to achieve is to fool the <em>discriminator</em> into thinking all generated data are real data. Train <em>generator</em> to minimize the loss function which is the difference between the discriminator’s feedback and the desired feedback: “All data are real data” (which is not true).</li>
</ul>
</section>
<section id="gan---schematic-process-iii" class="slide level2">
<h2>GAN - Schematic process III</h2>
<ul>
<li>When training, the discriminator may end up dominating the generator because the loss function for training the discriminator tends to zero faster. In that case, try reducing the learning rate and increase the dropout rate of the discriminator.</li>
<li>There are a few tricks for implementing GANS such as introducing stochasticity by adding random noise to the labels for the discriminator, using stride instead of pooling in the discriminator, using kernel size that is divisible by stride size, etc.</li>
</ul>
</section>
<section id="train-step" class="slide level2">
<h2>Train step</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="co"># Separate optimisers for discriminator and generator.</span></span>
<span id="cb3-2"><a></a>d_optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0003</span>)</span>
<span id="cb3-3"><a></a>g_optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0004</span>)</span>
<span id="cb3-4"><a></a></span>
<span id="cb3-5"><a></a><span class="co"># Instantiate a loss function.</span></span>
<span id="cb3-6"><a></a>loss_fn <span class="op">=</span> keras.losses.BinaryCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-7"><a></a></span>
<span id="cb3-8"><a></a><span class="at">@tf.function</span></span>
<span id="cb3-9"><a></a><span class="kw">def</span> train_step(real_images):</span>
<span id="cb3-10"><a></a>  <span class="co"># Sample random points in the latent space</span></span>
<span id="cb3-11"><a></a>  random_latent_vectors <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(batch_size, latent_dim))</span>
<span id="cb3-12"><a></a>  <span class="co"># Decode them to fake images</span></span>
<span id="cb3-13"><a></a>  generated_images <span class="op">=</span> generator(random_latent_vectors)</span>
<span id="cb3-14"><a></a>  <span class="co"># Combine them with real images</span></span>
<span id="cb3-15"><a></a>  combined_images <span class="op">=</span> tf.concat([generated_images, real_images], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-16"><a></a></span>
<span id="cb3-17"><a></a>  <span class="co"># Assemble labels discriminating real from fake images</span></span>
<span id="cb3-18"><a></a>  labels <span class="op">=</span> tf.concat([</span>
<span id="cb3-19"><a></a>    tf.zeros((batch_size, <span class="dv">1</span>)),</span>
<span id="cb3-20"><a></a>    tf.ones((real_images.shape[<span class="dv">0</span>], <span class="dv">1</span>))], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-21"><a></a></span>
<span id="cb3-22"><a></a>  <span class="co"># Add random noise to the labels - important trick!</span></span>
<span id="cb3-23"><a></a>  labels <span class="op">+=</span> <span class="fl">0.05</span> <span class="op">*</span> tf.random.uniform(labels.shape)</span>
<span id="cb3-24"><a></a></span>
<span id="cb3-25"><a></a>  <span class="co"># Train the discriminator</span></span>
<span id="cb3-26"><a></a>  <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb3-27"><a></a>    predictions <span class="op">=</span> discriminator(combined_images)</span>
<span id="cb3-28"><a></a>    d_loss <span class="op">=</span> loss_fn(labels, predictions)</span>
<span id="cb3-29"><a></a>  grads <span class="op">=</span> tape.gradient(d_loss, discriminator.trainable_weights)</span>
<span id="cb3-30"><a></a>  d_optimizer.apply_gradients(<span class="bu">zip</span>(grads, discriminator.trainable_weights))</span>
<span id="cb3-31"><a></a></span>
<span id="cb3-32"><a></a>  <span class="co"># Sample random points in the latent space</span></span>
<span id="cb3-33"><a></a>  random_latent_vectors <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(batch_size, latent_dim))</span>
<span id="cb3-34"><a></a></span>
<span id="cb3-35"><a></a>  <span class="co"># Assemble labels that say "all real images"</span></span>
<span id="cb3-36"><a></a>  misleading_labels <span class="op">=</span> tf.ones((batch_size, <span class="dv">1</span>))</span>
<span id="cb3-37"><a></a></span>
<span id="cb3-38"><a></a>  <span class="co"># Train the generator (note that we should *not* update the weights</span></span>
<span id="cb3-39"><a></a>  <span class="co"># of the discriminator)!</span></span>
<span id="cb3-40"><a></a>  <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb3-41"><a></a>    predictions <span class="op">=</span> discriminator(generator(random_latent_vectors))</span>
<span id="cb3-42"><a></a>    g_loss <span class="op">=</span> loss_fn(misleading_labels, predictions)</span>
<span id="cb3-43"><a></a></span>
<span id="cb3-44"><a></a>  grads <span class="op">=</span> tape.gradient(g_loss, generator.trainable_weights)</span>
<span id="cb3-45"><a></a>  g_optimizer.apply_gradients(<span class="bu">zip</span>(grads, generator.trainable_weights))</span>
<span id="cb3-46"><a></a>  <span class="cf">return</span> d_loss, g_loss, generated_images</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="grab-the-data" class="slide level2">
<h2>Grab the data</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="co"># Prepare the dataset.</span></span>
<span id="cb4-2"><a></a><span class="co"># We use both the training &amp; test MNIST digits.</span></span>
<span id="cb4-3"><a></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb4-4"><a></a>(x_train, _), (x_test, _) <span class="op">=</span> keras.datasets.mnist.load_data()</span>
<span id="cb4-5"><a></a>all_digits <span class="op">=</span> np.concatenate([x_train, x_test])</span>
<span id="cb4-6"><a></a>all_digits <span class="op">=</span> all_digits.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb4-7"><a></a>all_digits <span class="op">=</span> np.reshape(all_digits, (<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb4-8"><a></a>dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(all_digits)</span>
<span id="cb4-9"><a></a>dataset <span class="op">=</span> dataset.shuffle(buffer_size<span class="op">=</span><span class="dv">1024</span>).batch(batch_size)</span>
<span id="cb4-10"><a></a></span>
<span id="cb4-11"><a></a><span class="co"># In practice you need at least 20 epochs to generate nice digits.</span></span>
<span id="cb4-12"><a></a>epochs <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-13"><a></a>save_dir <span class="op">=</span> <span class="st">"./"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="train-the-gan" class="slide level2">
<h2>Train the GAN</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="op">%%</span>time</span>
<span id="cb5-2"><a></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb5-3"><a></a>  <span class="cf">for</span> step, real_images <span class="kw">in</span> <span class="bu">enumerate</span>(dataset):</span>
<span id="cb5-4"><a></a>    <span class="co"># Train the discriminator &amp; generator on one batch of real images.</span></span>
<span id="cb5-5"><a></a>    d_loss, g_loss, generated_images <span class="op">=</span> train_step(real_images)</span>
<span id="cb5-6"><a></a></span>
<span id="cb5-7"><a></a>    <span class="co"># Logging.</span></span>
<span id="cb5-8"><a></a>    <span class="cf">if</span> step <span class="op">%</span> <span class="dv">200</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-9"><a></a>      <span class="co"># Print metrics</span></span>
<span id="cb5-10"><a></a>      <span class="bu">print</span>(<span class="ss">f"Discriminator loss at step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>d_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-11"><a></a>      <span class="bu">print</span>(<span class="ss">f"Adversarial loss at step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>g_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-12"><a></a>      <span class="cf">break</span> <span class="co"># Remove this if really training the GAN</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section></section>
<section>
<section id="conditional-gans" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Conditional GANs</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Traditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Training GANs</p>
</div></li>
<li><div class="agenda-active">
<p>Conditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Image-to-image translation</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Problems with GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Wasserstein GAN</p>
</div></li>
</ul>
</div>
</section>
<section id="unconditional-gans" class="slide level2">
<h2>Unconditional GANs</h2>

<img data-src="coursera-unconditional-gan.png" class="r-stretch quarto-figure-center"><p class="caption">Analogy for an unconditional GAN</p><div class="footer">
<p>Source: Sharon Zhou, <em>Conditional Generation: Intuition</em> Build Basic Generative Adversarial Networks (Week 4), DeepLearning.AI on Coursera.</p>
</div>
</section>
<section id="conditional-gans-1" class="slide level2">
<h2>Conditional GANs</h2>

<img data-src="coursera-conditional-gan.png" class="r-stretch quarto-figure-center"><p class="caption">Analogy for a conditional GAN</p><div class="footer">
<p>Source: Sharon Zhou, <em>Conditional Generation: Intuition</em> Build Basic Generative Adversarial Networks (Week 4), DeepLearning.AI on Coursera.</p>
</div>
</section>
<section id="hurricane-example-data" class="slide level2">
<h2>Hurricane example data</h2>

<img data-src="hurricane/reals.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Original data</p></section>
<section id="hurricane-example" class="slide level2" data-visibility="uncounted">
<h2>Hurricane example</h2>

<img data-src="hurricane/fakes_init.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Initial fakes</p></section>
<section id="hurricane-example-after-54s" class="slide level2" data-visibility="uncounted">
<h2>Hurricane example (after 54s)</h2>

<img data-src="hurricane/fakes000000.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Fakes after 1 iteration</p></section>
<section id="hurricane-example-after-21m" class="slide level2" data-visibility="uncounted">
<h2>Hurricane example (after 21m)</h2>

<img data-src="hurricane/fakes000100.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Fakes after 100 kimg</p></section>
<section id="hurricane-example-after-47m" class="slide level2" data-visibility="uncounted">
<h2>Hurricane example (after 47m)</h2>

<img data-src="hurricane/fakes000200.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Fakes after 200 kimg</p></section>
<section id="hurricane-example-after-4h10m" class="slide level2" data-visibility="uncounted">
<h2>Hurricane example (after 4h10m)</h2>

<img data-src="hurricane/fakes001000.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Fakes after 1000 kimg</p></section>
<section id="hurricane-example-after-14h41m" class="slide level2" data-visibility="uncounted">
<h2>Hurricane example (after 14h41m)</h2>

<img data-src="hurricane/fakes003700.jpeg" class="r-stretch quarto-figure-center"><p class="caption">Fakes after 3700 kimg</p></section></section>
<section>
<section id="image-to-image-translation" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Image-to-image translation</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Traditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Training GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Conditional GANs</p>
</div></li>
<li><div class="agenda-active">
<p>Image-to-image translation</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Problems with GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Wasserstein GAN</p>
</div></li>
</ul>
</div>
</section>
<section id="example-deoldify-images-1" class="slide level2">
<h2>Example: Deoldify images #1</h2>

<img data-src="deoldify-migrant-mother.jpeg" class="r-stretch quarto-figure-center"><p class="caption">A deoldified version of the famous “Migrant Mother” photograph.</p><div class="footer">
<p>Source: <a href="https://github.com/jantic/DeOldify">Deoldify package</a>.</p>
</div>
</section>
<section id="example-deoldify-images-2" class="slide level2">
<h2>Example: Deoldify images #2</h2>

<img data-src="deoldify-golden-gate-bridge.jpeg" class="r-stretch quarto-figure-center"><p class="caption">A deoldified Golden Gate Bridge under construction.</p><div class="footer">
<p>Source: <a href="https://github.com/jantic/DeOldify">Deoldify package</a>.</p>
</div>
</section>
<section id="example-deoldify-images-3" class="slide level2">
<h2>Example: Deoldify images #3</h2>
<div class="columns">
<div class="column">
<p><img data-src="dog-bw.jpeg"></p>
</div><div class="column">
<p><img data-src="dog-colour.jpeg"></p>
</div></div>
</section>
<section id="explore-the-latent-space" class="slide level2">
<h2>Explore the latent space</h2>
<iframe data-external="1" src="https://www.youtube.com/embed/rr_ARby64lw" width="1000px" height="600px" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</section>
<section id="generator-cant-generate-everything" class="slide level2">
<h2>Generator can’t generate everything</h2>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="StyleGAN2-ADA-Latent-Space/target.png"></p>
<figcaption>Target</figcaption>
</figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="StyleGAN2-ADA-Latent-Space/proj.png"></p>
<figcaption>Projection</figcaption>
</figure>
</div>
</div></div>
</section></section>
<section>
<section id="problems-with-gans" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Problems with GANs</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Traditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Training GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Conditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Image-to-image translation</p>
</div></li>
<li><div class="agenda-active">
<p>Problems with GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Wasserstein GAN</p>
</div></li>
</ul>
</div>
</section>
<section id="they-are-slow-to-train" class="slide level2">
<h2>They are slow to train</h2>
<p>StyleGAN2-ADA training times on V100s (1024x1024):</p>
<table class="caption-top">
<colgroup>
<col style="width: 6%">
<col style="width: 22%">
<col style="width: 20%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">GPUs</th>
<th style="text-align: center;">1000 kimg</th>
<th style="text-align: center;">25000 kimg</th>
<th style="text-align: center;">sec / kimg</th>
<th style="text-align: center;">GPU mem</th>
<th style="text-align: center;">CPU mem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1d 20h</td>
<td style="text-align: center;">46d 03h</td>
<td style="text-align: center;">158</td>
<td style="text-align: center;">8.1 GB</td>
<td style="text-align: center;">5.3 GB</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">23h 09m</td>
<td style="text-align: center;">24d 02h</td>
<td style="text-align: center;">83</td>
<td style="text-align: center;">8.6 GB</td>
<td style="text-align: center;">11.9 GB</td>
</tr>
<tr class="odd">
<td style="text-align: center;">4</td>
<td style="text-align: center;">11h 36m</td>
<td style="text-align: center;">12d 02h</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">8.4 GB</td>
<td style="text-align: center;">21.9 GB</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">5h 54m</td>
<td style="text-align: center;">6d 03h</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">8.3 GB</td>
<td style="text-align: center;">44.7 GB</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Source: NVIDIA’s Github, <a href="https://github.com/NVlabs/stylegan2-ada-pytorch/">StyleGAN2-ADA — Official PyTorch implementation</a>.</p>
</div>
</section>
<section id="uncertain-convergence" class="slide level2">
<h2>Uncertain convergence</h2>
<p>Converges to a Nash equilibrium.. if at all.</p>

<img data-src="lilian-weng-unstable-convergence.png" class="r-stretch quarto-figure-center"><p class="caption">Analogy of minimax update failure.</p><div class="footer">
<p>Source: Lilian Weng (2019), <em>From GAN to WGAN</em>, ArXiV.</p>
</div>
</section>
<section id="mode-collapse" class="slide level2 smaller">
<h2>Mode collapse</h2>
<div class="columns">
<div class="column" style="width:50%&quot;;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="gan-mode-collapse.png"></p>
<figcaption>Example of mode collapse</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<p><img data-src="xkcd-random_number.png"></p>
</div></div>
<div class="footer">
<p>Source: Metz et al.&nbsp;(2017), <a href="https://arxiv.org/pdf/1611.02163.pdf">Unrolled Generative Adversarial Networks</a> and Randall Munroe (2007), <a href="https://xkcd.com/221/">xkcd #221: Random Number</a>.</p>
</div>
</section>
<section id="generation-is-harder" class="slide level2">
<h2>Generation is harder</h2>

<img data-src="gan-diagram.png" class="r-stretch quarto-figure-center"><p class="caption">A schematic of a generative adversarial network.</p><div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="co"># Separate optimisers for discriminator and generator.</span></span>
<span id="cb6-2"><a></a>d_optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0003</span>)</span>
<span id="cb6-3"><a></a>g_optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0004</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="footer">
<p>Source: Thales Silva (2018), <a href="https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394">An intuitive introduction to Generative Adversarial Networks (GANs)</a>, freeCodeCamp.</p>
</div>
</section>
<section id="advanced-image-layers" class="slide level2 smaller">
<h2>Advanced image layers</h2>
<div class="absolute" style="top: 120px; left: 250px; ">
<p>Conv2D</p>
</div>
<div class="absolute" style="top: 270px; left: 60px; ">
<p>GlobalMaxPool2D</p>
</div>
<div class="absolute" style="top: 270px; right: 100px; ">
<p>Conv2DTranspose</p>
</div>
<p><img data-src="2d_global_max_pooling_pa1.png" class="absolute" style="left: 0px; bottom: 0px; width: 550px; "></p>
<p><img data-src="conv2d.gif" class="absolute" style="top: 75px; left: 350px; width: 300px; "></p>
<p><img data-src="conv2dTranspose.gif" class="absolute" style="bottom: 0px; right: 50px; width: 300px; "></p>
<div class="footer">
<p>Sources: Pröve (2017), <a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">An Introduction to different Types of Convolutions in Deep Learning</a>, and Peltarion Knowledge Center, <a href="https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/global-max-pooling-2d">Global max pooling 2D</a>.</p>
</div>
</section>
<section id="vanishing-gradients-i" class="slide level2">
<h2>Vanishing gradients (I)</h2>

<img data-src="coursera-vanishing-gradients.png" class="r-stretch quarto-figure-center"><p class="caption">When the discriminator is too good, vanishing gradients</p><div class="footer">
<p>Source: Sharon Zhou, <em>Problem with BCE Loss</em>, Build Basic Generative Adversarial Networks (Week 3), DeepLearning.AI on Coursera.</p>
</div>
</section>
<section id="vanishing-gradients-ii" class="slide level2">
<h2>Vanishing gradients (II)</h2>

<img data-src="lilian-weng-vanishing-gradients.png" class="r-stretch quarto-figure-center"><p class="caption">Vanishing gradients</p><div class="footer">
<p>Source: Lilian Weng (2019), <em>From GAN to WGAN</em>, ArXiV.</p>
</div>
</section></section>
<section>
<section id="wasserstein-gan" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Wasserstein GAN</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Traditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Training GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Conditional GANs</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Image-to-image translation</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Problems with GANs</p>
</div></li>
<li><div class="agenda-active">
<p>Wasserstein GAN</p>
</div></li>
</ul>
</div>
</section>
<section id="were-comparing-distributions" class="slide level2">
<h2>We’re comparing distributions</h2>
<p>Trying to minimise the distance between the <em>distribution of generated samples</em> and the <em>distribution of real data</em>.</p>
<p>Vanilla GAN is equivalent to minimising the Jensen–Shannon Divergence between the two.</p>
<p>An alternative distance between distributions is the <em>Wasserstein distance</em>.</p>
</section>
<section id="discriminator-critic" class="slide level2">
<h2><del>Discriminator</del> Critic</h2>
<p>Critic <span class="math inline">D : \text{Input} \to \mathbb{R}</span> how “authentic” the input looks. It can’t discriminate real from fake exactly.</p>
<p>Critic’s goal is</p>
<p><span class="math display"> \max_{D \in \mathscr{D}} \mathbb{E}[ D(X) ] - \mathbb{E}[ D(G(Z)) ] </span></p>
<p>where we <span class="math inline">\mathscr{D}</span> is space of 1-Lipschitz functions. Either use <em>gradient clipping</em> or penalise gradients far from 1:</p>
<p><span class="math display"> \max_{D} \mathbb{E}[ D(X) ] - \mathbb{E}[ D(G(Z)) ] + \lambda \mathbb{E} \Bigl[ ( \bigl|\bigl| \nabla D \bigr|\bigr| - 1)^2 \Bigr] .  </span></p>
</section>
<section id="schematic" class="slide level2">
<h2>Schematic</h2>

<img data-src="wasserstein-schematic.png" class="r-stretch quarto-figure-center"><p class="caption">Wasserstein</p><div class="footer">
<p>Source: Côté et al.&nbsp;(2020), <em>Synthesizing Property &amp; Casualty Ratemaking Datasets using Generative Adversarial Networks</em>, Working Paper?.</p>
</div>
</section>
<section id="links" class="slide level2 appendix" data-visibility="uncounted">
<h2>Links</h2>
<ul>
<li>Dongyu Liu (2021), <a href="https://youtu.be/jIDj2dhU99k">TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks</a></li>
<li>Jeff Heaton (2022), <a href="https://youtu.be/yujdA46HKwA">GANs for Tabular Synthetic Data Generation (7.5)</a></li>
<li>Jeff Heaton (2022), <a href="https://youtu.be/0OTd5GlHRx4">GANs to Enhance Old Photographs Deoldify (7.4)</a></li>
</ul>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../unsw-logo.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"boardmarkerWidth":4,"grid":false,"background":["rgba(255,255,255,0.0)","https://github.com/rajgoel/reveal.js-plugins/raw/master/chalkboard/img/blackboard.png"]},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1000,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
            // Handle positioning of the toggle
        window.addEventListener(
          "resize",
          throttle(() => {
            elRect = undefined;
            if (selectedAnnoteEl) {
              selectCodeLines(selectedAnnoteEl);
            }
          }, 10)
        );
        function throttle(fn, ms) {
        let throttle = false;
        let timer;
          return (...args) => {
            if(!throttle) { // first call gets through
                fn.apply(this, args);
                throttle = true;
            } else { // all the others get throttled
                if(timer) clearTimeout(timer); // cancel #2
                timer = setTimeout(() => {
                  fn.apply(this, args);
                  timer = throttle = false;
                }, ms);
            }
          };
        }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>