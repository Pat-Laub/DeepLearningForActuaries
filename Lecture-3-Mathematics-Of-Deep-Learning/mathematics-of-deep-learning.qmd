---
title: Mathematics of Deep Learning 
subtitle: "ACTL3143/5111: Deep Learning for Actuaries"
author: Dr Patrick Laub
date: Week 3
format:
  revealjs:
    theme: [serif, custom.scss]
    controls: true
    controls-tutorial: true
    logo: unsw-logo.svg
    footer: "Slides: [Dr Patrick Laub](https://pat-laub.github.io) (@PatrickLaub)."
    title-slide-attributes:
      data-background-image: unsw-yellow-shape.png
      data-background-size: contain !important
    transition: none
    slide-number: c/t
    strip-comments: true
    preview-links: false
    margin: 0.12
    width: 1000
    chalkboard:
      boardmarker-width: 6
      grid: false
      background:
        - "rgba(255,255,255,0.0)"
        - "https://github.com/rajgoel/reveal.js-plugins/raw/master/chalkboard/img/blackboard.png"
    include-before: |
      <div class="line right"></div>
      <!--<link rel="stylesheet" href="https://pyscript.net/alpha/pyscript.css" />-->
      <script defer src="https://pyscript.net/alpha/pyscript.js"></script>
      <py-env>
        - matplotlib
      </py-env>
    include-after: <script>registerRevealCallbacks();</script>
highlight-style: breeze
jupyter: python3
execute:
  keep-ipynb: true
  echo: true
---

```{python}
#| echo: false
import matplotlib

import cycler
colors = ["#91CCCC", "#FF8FA9", "#CC91BC", "#3F9999", "#A5FFB8"]
matplotlib.pyplot.rcParams["axes.prop_cycle"] = cycler.cycler(color=colors)

def set_square_figures():
  matplotlib.pyplot.rcParams['figure.figsize'] = (2.0, 2.0)

def set_rectangular_figures():
  matplotlib.pyplot.rcParams['figure.figsize'] = (5.0, 2.0)

set_rectangular_figures()
matplotlib.pyplot.rcParams['figure.dpi'] = 350
matplotlib.pyplot.rcParams['savefig.bbox'] = "tight"
matplotlib.pyplot.rcParams['font.family'] = "serif"

matplotlib.pyplot.rcParams['axes.spines.right'] = False
matplotlib.pyplot.rcParams['axes.spines.top'] = False

def squareFig():
    return matplotlib.pyplot.figure(figsize=(2, 2), dpi=350).gca()

def add_diagonal_line():
    xl = matplotlib.pyplot.xlim()
    yl = matplotlib.pyplot.ylim()
    shortestSide = min(xl[1], yl[1])
    matplotlib.pyplot.plot([0, shortestSide], [0, shortestSide], color="black", linestyle="--")

import pandas
pandas.options.display.max_rows = 6

import numpy
numpy.set_printoptions(precision=2)
numpy.random.seed(123)

import tensorflow
tensorflow.random.set_seed(1)
tensorflow.config.set_visible_devices([], 'GPU')
```

## Lecture Outline 

- Early stopping
- Classification
- Poisson loss and SW #2
- Optimisation
- Python: Objects, classes, lambdas

Thurs office hours (Outlook).

## Load packages {data-visibility="uncounted"}

<br>
<br>

```{python}
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
```

# Validation Sets {background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

```{python}
#| echo: false
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.datasets import fetch_california_housing
features, target = fetch_california_housing(as_frame=True, return_X_y=True)

mseTrainPrev = {'Linear Regression': 0.5205522163645129,
 'Basic ANN': 0.8213997980052227,
 'Long run ANN': 0.6608583727274803,
 'Exp ANN': 0.3220443619821428}

mseTestPrev = {'Linear Regression': 0.5411287478470694,
 'Basic ANN': 0.7963672291024868,
 'Long run ANN': 0.6279579206481324,
 'Exp ANN': 0.3295336955821915}
```

## California housing dataset {data-visibility="uncounted"}

```{python}
features.sample(3, random_state=4)
```

```{python}
target.sample(3, random_state=4)
```

## Questions to answer in ML project

<br>

You fit a few models to the training set, then ask:

<br>

1. __(Selection)__ Which of these models is the best?
2. __(Future Performance)__ How good should we expect the final model to be on unseen data?

## Basic ML workflow

![Splitting the data.](wiki-ML_dataset_training_validation_test_sets.png)

1. For each model, fit it to the _training set_.
2. Compute the error for each model on the _validation set_.
3. Select the model with the lowest validation error.
4. Compute the error of the final model on the _test set_.

::: footer
Source: [Wikipedia](https://commons.wikimedia.org/wiki/File:ML_dataset_training_validation_test_sets.png#filelinks).
:::

## _Diviser en trois_ (split three ways)

<br>

```{python}
# Thanks https://datascience.stackexchange.com/a/15136
X_main, X_test, y_main, y_test = \
    train_test_split(features, target, test_size=0.2, random_state=1)

# As 0.25 x 0.8 = 0.2
X_train, X_val, y_train, y_val = \
    train_test_split(X_main, y_main, test_size=0.25, random_state=1)

X_train.shape, X_val.shape, X_test.shape
```

```{python}
#| echo: false
NUM_FEATURES = len(features.columns)

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train, y_train);

mseTrain = {"Linear Regression": mean_squared_error(y_train, lr.predict(X_train))}
mseVal = {"Linear Regression": mean_squared_error(y_val, lr.predict(X_val))}

tf.random.set_seed(1234)

model = Sequential([
    Dense(30, activation="relu"),
    Dense(1)
])
model.compile("adam", "mse")

model.fit(X_train, y_train, epochs=5, verbose=False)

mseTrain["Basic ANN"] = model.evaluate(X_train, y_train, verbose=False)
mseVal["Basic ANN"] = model.evaluate(X_val, y_val, verbose=False)

tf.random.set_seed(1234)

model = Sequential([
    Dense(30, activation="relu"),
    Dense(1)
])
model.compile("adam", "mse")

model.fit(X_train, y_train, \
    epochs=100, verbose=False)

mseTrain["Long run ANN"] = model.evaluate(X_train, y_train, verbose=False)
mseVal["Long run ANN"] = model.evaluate(X_val, y_val, verbose=False)
```

## Retrain last week's models

... on the new train set (just showing the last one here).

```{python}
sc = StandardScaler()
sc.fit(X_train)
X_train_sc = sc.transform(X_train)
X_val_sc = sc.transform(X_val)
X_test_sc = sc.transform(X_test)

tf.random.set_seed(1234)
model = Sequential([
    Dense(30, activation="relu"),
    Dense(1, activation="exponential")
])
model.compile("adam", "mse")
%time hist = model.fit(X_train_sc, y_train, epochs=100, verbose=False)

mseTrain["Exp ANN"] = mean_squared_error(y_train, model.predict(X_train_sc))
mseVal["Exp ANN"] = mean_squared_error(y_val, model.predict(X_val_sc))
```

## Comparing on Week 2's ~~test~~ val set {data-visibility="uncounted"}


```{python}
#| echo: false
testResults = pd.DataFrame({"Model": mseTestPrev.keys(), "MSE": mseTestPrev.values()})
testResults.sort_values("MSE", ascending=False)
```

## Comparing on validation set {data-visibility="uncounted"}


```{python}
#| echo: false
valResults = pd.DataFrame({"Model": mseVal.keys(), "MSE": mseVal.values()})
valResults.sort_values("MSE", ascending=False)
```

::: fragment
Evaluate _only the final/selected model_ on the test set.

```{python}
mean_squared_error(y_test, model.predict(X_test_sc))
```

```{python}
model.evaluate(X_test_sc, y_test, verbose=False)
```
:::

## Why not use test set for both?

_Thought experiment_: have $m$ classifiers: $f_1(\mathbf{x})$, $\dots$, $f_m(\mathbf{x})$.

They are just as good as each other in the long run
$$
\mathbb{P}(\, f_i(\mathbf{X}) = Y \,)\ =\ 90\% , \quad \text{for } i=1,\dots,m .
$$

::: columns
::: {.column width="40%"}
Evaluate each model on the test set, some will be better than others.

:::
::: {.column width="60%"}
```{python}
#| echo: false
# set_square_figures()
np.random.seed(123)
m = 50
x = np.random.normal(loc=0.9, scale=0.03, size=m)
sns.distplot(x)
plt.scatter(x, np.zeros_like(x))
plt.xlabel("Accuracy of each model on test set")
plt.axvline(0.9, ls='--', c='k');
plt.axvline(np.max(x), ls='--', c='r');
plt.tight_layout()
# set_rectangular_figures()
```
:::
:::

Take the best, you'd think it has $\approx 98\%$ accuracy!

# Early Stopping {background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

## Choosing when to stop training

![Illustrative loss curves over time.](heaton-error-over-time.png)

::: footer
Source: Heaton (2022), [Applications of Deep Learning](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_03_4_early_stop.ipynb), Part 3.4: Early Stopping.
:::

## Try early stopping

Hinton calls it a "beautiful free lunch"

```{python}
#| code-line-numbers: "|1,10,13"
from tensorflow.keras.callbacks import EarlyStopping

tf.random.set_seed(1234)
model = Sequential([
    Dense(30, activation="relu"),
    Dense(1, activation="exponential")
])
model.compile("adam", "mse")

es = EarlyStopping(restore_best_weights=True, patience=10)

%time hist = model.fit(X_train_sc, y_train, epochs=1_000, \
    callbacks=[es], validation_data=(X_val_sc, y_val), verbose=False)
print(f"Keeping model at epoch #{len(hist.history['loss'])-10}.")
```

## Loss curve

```{python}
plt.plot(hist.history["loss"])
plt.plot(hist.history["val_loss"])
plt.legend(["Training", "Validation"]);
```

## Predictions

```{python}
#| echo: false
set_square_figures()
```

::: columns
::: column
```{python}
#| echo: false
y_pred = model.predict(X_train_sc)
plt.scatter(y_pred, y_train)
plt.xlabel("Predictions")
plt.ylabel("True values")
plt.title("Training set")
add_diagonal_line()
```
:::
::: column
```{python}
#| echo: false
y_pred = model.predict(X_val_sc)
plt.scatter(y_pred, y_val)
plt.xlabel("Predictions")
plt.ylabel("True values")
plt.title("Validation set")
add_diagonal_line()
```
:::
:::

```{python}
#| echo: false
set_rectangular_figures()
```

```{python}
#| echo: false
# Store the results
mseTrain["Early stop ANN"] = model.evaluate(X_train_sc, y_train, verbose=False)
mseVal["Early stop ANN"] = model.evaluate(X_val_sc, y_val, verbose=False)
```

## Comparing models (validation set) {data-visibility="uncounted"}

<br>

```{python}
#| echo: false
valResults = pd.DataFrame({"Model": mseVal.keys(), "MSE": mseVal.values()})
valResults.sort_values("MSE", ascending=False)
```

## Other callbacks

```{python}
from tensorflow.keras.callbacks import ModelCheckpoint

tf.random.set_seed(1234)
model = Sequential([
    Dense(30, activation="relu"),
    Dense(1, activation="exponential")
])
model.compile("adam", "mse")

# On Colab, save models to Google Drive.
mc = ModelCheckpoint("best-model.h5", monitor="val_loss",
        save_best_only=True)
es = EarlyStopping(restore_best_weights=True, patience=5)

hist = model.fit(X_train_sc, y_train, epochs=100, \
    validation_split=0.1, callbacks=[mc, es], verbose=False)

!file best-model.h5 && du -sh best-model.h5
```

```{python}
#| echo: false
!rm best-model.h5
```

# Classification {background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

```{python}
#| echo: false
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split

tensorflow.config.set_visible_devices([], "GPU")

pandas.options.display.max_rows = 4
```

## Iris dataset

```{python}
from sklearn.datasets import load_iris
iris = load_iris()
names = ["SepalLength", "SepalWidth", "PetalLength", "PetalWidth"]
features = pd.DataFrame(iris.data, columns = names)
features
```

## Target variable

::: columns
::: column

```{python}
iris.target_names
```

```{python}
iris.target[:8]
```

```{python}
target = iris.target
target = target.reshape(-1, 1)
target[:8]
```
:::
::: column
```{python}
classes, counts = np.unique(
        target,
        return_counts=True
)
print(classes)
print(counts)
```

```{python}
iris.target_names[
  target[[0, 30, 60]]
]
```
:::
:::

```{python}
#| echo: false
pandas.options.display.max_rows = 6
```


## Split the data into train and test {.smaller}

```{python}
X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=24)
X_train
```

```{python}
X_test.shape, y_test.shape
```

## A basic classifier network

![A basic network for classifying into three categories.](Geron-mls2_1009-blur.png)

::: footer
Source: Aur√©lien G√©ron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Fig. 10-09 (__redacted__).
:::

## Create a classifier model

```{python}
NUM_FEATURES = len(features.columns)
NUM_CATS = len(np.unique(target))

print("Number of features:", NUM_FEATURES)
print("Number of categories:", NUM_CATS)
```

Make a function to return a Keras model:
```{python}
def build_model(seed=42):
    tf.random.set_seed(seed)
    return Sequential([
        Dense(30, activation="relu"),
        Dense(NUM_CATS, activation="softmax")
    ])
```

## Fit the model

```{python}
model = build_model()
model.compile("adam", "SparseCategoricalCrossentropy")

model.fit(X_train, y_train, epochs=5, verbose=2);
```

## Track accuracy as the model trains

```{python}
model = build_model()
model.compile("adam", "SparseCategoricalCrossentropy", \
        metrics=["accuracy"])
model.fit(X_train, y_train, epochs=5, verbose=2);
```

## Run a long fit

```{python}

model = build_model()
model.compile("adam", "SparseCategoricalCrossentropy", \
        metrics=["accuracy"])
%time hist = model.fit(X_train, y_train, epochs=500, \
        validation_split=0.25, verbose=False)
```

Evaluation now returns both _loss_ and _accuracy_.
```{python}
model.evaluate(X_test, y_test, verbose=False)
```

## Add early stopping

```{python}
model = build_model()
model.compile("adam", "SparseCategoricalCrossentropy", \
        metrics=["accuracy"])

es = EarlyStopping(restore_best_weights=True, patience=50,
        monitor="val_accuracy")
%time histES = model.fit(X_train, y_train, epochs=500, \
        validation_split=0.25, callbacks=[es], verbose=False);

print(f"Stopped after {len(histES.history['loss'])} epochs.")
```

Evaluation on test set:
```{python}
model.evaluate(X_test, y_test, verbose=False)
```

## Fitting metrics

::: columns
::: column
```{python}
#| echo: false
matplotlib.pyplot.rcParams["figure.figsize"] = (2.5, 2.95)
plt.subplot(2, 1, 1)
plt.plot(hist.history["loss"])
plt.plot(hist.history["val_loss"])
plt.title("Loss")
plt.legend(["Training", "Validation"]);

plt.subplot(2, 1, 2)
plt.plot(histES.history["loss"])
plt.plot(histES.history["val_loss"])
plt.xlabel("Epoch");
```
:::
::: column
```{python}
#| echo: false
matplotlib.pyplot.rcParams["figure.figsize"] = (2.5, 3.25) 
plt.subplot(2, 1, 1)
plt.plot(hist.history["accuracy"])
plt.plot(hist.history["val_accuracy"])
plt.title("Accuracy")

plt.subplot(2, 1, 2)
plt.plot(histES.history["accuracy"])
plt.plot(histES.history["val_accuracy"])
plt.xlabel("Epoch");
```
:::
:::

```{python}
#| echo: false
set_rectangular_figures()
```


## What is the softmax activation?

It creates a "probability" vector: $\text{Softmax}(\boldsymbol{x}) = \frac{\mathrm{e}^x_i}{\sum_j \mathrm{e}^x_j} \,.$

In NumPy:
```{python}
out = np.array([5, -1, 6])
(np.exp(out) / np.exp(out).sum()).round(3)
```

In TensorFlow:
```{python}
out = tf.constant([[5.0, -1.0, 6.0]])
tf.keras.activations.softmax(out).numpy().round(3)
```

## Prediction using classifiers

```{python}
y_test[:4]
```

```{python}
y_pred = model.predict(X_test.head(4))
y_pred
```

```{python}
# Add 'keepdims=True' to get a column vector.
np.argmax(y_pred, axis=1)
```

```{python}
iris.target_names[np.argmax(y_pred, axis=1)]
```

## Why use cross-entropy loss?

```{python}
p = np.linspace(0, 1, 100)
plt.plot(p, (1-p)**2)
plt.plot(p, -np.log(p))
plt.legend(["MSE", "Cross-entropy"]);
```

## One-hot encoding

```{python}
from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder()
enc.fit(y_train) # May need .reshape(-1, 1)
y_train_oh = enc.transform(y_train)
y_test_oh = enc.transform(y_test)
```

::: columns
::: column
```{python}
y_train[:5]
```
:::
::: column
```{python}
y_train_oh[:5]
```
:::
:::

## One-hot encoding {data-visibility="uncounted"}

```{python}
from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder(sparse=False)

y_train_oh = enc.fit_transform(y_train)
y_test_oh = enc.transform(y_test)
```

::: columns
::: column
```{python}
y_train[:5]
```
:::
::: column
```{python}
y_train_oh[:5]
```
:::
:::

## Classifier given one-hot outputs

<br>

Create the model (_new loss function_):
```{python}
#| code-line-numbers: "|3"
model = build_model()
model.compile("adam", "CategoricalCrossentropy", \
    metrics=["accuracy"])
```

Fit the model (_new target variables_):
```{python}
model.fit(X_train, y_train_oh, epochs=100, verbose=False);
```

Evaluate the model (_new target variables_):
```{python}
model.evaluate(X_test, y_test_oh, verbose=False)
```


# Quiz {data-background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

```{python}
#| echo: false
import numpy

numpy.random.seed(123)
x = numpy.random.rand(100)
y = 1_000 * numpy.random.rand(100)
z = 2*x + 0.001 * y + 1 + 1 * numpy.random.rand(100)

# X = np.c_[x, y]
# features = X
features = pandas.DataFrame({"$x_1$": x, "$x_2$": y})
targets = z
```

## Critique this üí© regression code

```{python}
#| echo: false
from tensorflow.keras.callbacks import EarlyStopping
tf.get_logger().setLevel('ERROR')
```

```{python}
X_train = features[:80]; X_test = features[81:]
y_train = targets[:80]; y_test = targets[81:]
```
```{python}
model = Sequential([
  Dense(32, activation='ReLU', input_dim=2),
   Dense(32, activation='ReLU', input_dim=2),
  Dense(1, activation='sigmoid')
])
model.compile(optimizer="adam", loss='mse')
es = EarlyStopping(patience=10)
fitted_model = model.fit(X_train, y_train, epochs=5,
  callbacks=[es], verbose=False)
```
```{python}
trainMAE = model.evaluate(X_train, y_train, verbose=False)
hist = model.fit(X_test, y_test, epochs=5,
  callbacks=[es], verbose=False)
hist.history["loss"]
testMAE = model.evaluate(X_test, y_test, verbose=False)
```

```{python}
f"Train MAE: {testMAE:.2f} Test MAE: {trainMAE:.2f}"
```

## The data

```{python}
#| echo: false
set_square_figures()
```

::: columns
::: column
```{python}
sns.scatterplot(
  x="$x_1$", y="$x_2$",
  c=targets, data=features);
```
:::
::: column
```{python}
sns.distplot(targets);
```

:::
:::

```{python}
#| echo: false
set_rectangular_figures()
```

## With warnings enabled

```{python}
#| echo: false
tf.get_logger().setLevel("WARN")
```

```{python}
model.fit(X_train, y_train, epochs=5,
  callbacks=[es], verbose=False);
```

```{python}
es = EarlyStopping(restore_best_weights=True, patience=10)
model.fit(X_train, y_train, epochs=5, validation_split=0.1,
  callbacks=[es], verbose=False);
```

## Later `input_dim` ignored

```{python}
#| echo: false
def skip_empty(line):
  if line.strip() != "":
    print(line.strip())
```

```{python}
model = Sequential([
  Dense(32, activation='ReLU', input_dim=2),
  Dense(32, activation='ReLU', input_dim=2),
  Dense(1, activation='ReLU')
])

model.compile(optimizer='adam', loss='mse')
model.summary(print_fn=skip_empty)
```

## Later `input_dim` ignored {data-visibility="uncounted"}

```{python}
model = Sequential([
  Dense(32, activation='ReLU', input_dim=2),
  Dense(32, activation='ReLU'),
  Dense(1, activation='ReLU')
])

model.compile(optimizer='adam', loss='mse')
model.summary(print_fn=skip_empty)
```

## Later `input_dim` ignored {data-visibility="uncounted"}

```{python}
model = Sequential([
  Dense(32, activation='ReLU'),
  Dense(32, activation='ReLU'),
  Dense(1, activation='ReLU')
])
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=5, verbose=False)
model.summary(print_fn=skip_empty)
```


# Poisson Regression, Deviance & Loss {background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

## French motor dataset

```{python}
#| echo: false
from sklearn.datasets import fetch_openml

# Download the dataset if it hasn't already been downloaded.
from pathlib import Path
cd = Path(".")
if (cd / "freq_data.csv").exists():
    freq = pandas.read_csv("freq_data.csv")
else:
    print("Downloading dataset...")
    from sklearn.datasets import fetch_openml
    freq = fetch_openml(data_id=41214, as_frame=True).frame
    freq.to_csv("freq_data.csv", index=False)

# Remove the column named 'IDpol'.
freq = freq.drop("IDpol", axis=1)

# Convert categorical variables to numeric.
freq = pandas.get_dummies(freq, columns=["VehGas", "Area", "VehBrand", "Region"])
```

```{python}
freq.drop("ClaimNb", axis=1).sample(3, random_state=6)
```

```{python}
freq["ClaimNb"].sample(3, random_state=6)
```

## Where are things defined?

String options in Keras are just conveniences.

```{python}
model = Sequential([
    Dense(30, activation="relu"),
    Dense(1, activation="exponential")
])
```

is the same as

```{python}
from tensorflow.keras.activations import relu, exponential

model = Sequential([
    Dense(30, activation=relu),
    Dense(1, activation=exponential)
])
```

```{python}
x = [-1.0, 0.0, 1.0]
print(relu(x))
print(exponential(x))
```

## String arguments to `.compile`

When we run

```{python}
model.compile(optimizer="adam", loss="poisson")
```

it is equivalent to

```{python}
from tensorflow.keras.losses import poisson
from tensorflow.keras.optimizers import Adam

model.compile(optimizer=Adam(), loss=poisson)
```

Why do this manually? To adjust the object:

```{python}
optimizer = Adam(learning_rate=0.01)
model.compile(optimizer=optimizer, loss="poisson")
```

or to get help.

## Asked to use the "poisson" loss

```{python}
help(tf.keras.losses.poisson)
```

## The model

Have $\{ (\mathbf{x}_i, y_i) \}_{i=1, \dots, n}$ for $\mathbf{x}_i \in \mathbb{R}^{47}$ and $y_i \in \mathbb{N}_0$.

Assume the distribution
$$
Y_i \sim \mathsf{Poisson}(\lambda(\mathbf{x}_i))
$$

We have $\mathbb{E} Y_i = \lambda(\mathbf{x}_i)$. 
The NN takes $\mathbf{x}_i$ and predicts $\mathbb{E} Y_i$.

::: {.callout-note}
For insurance, _this is a bit weird_.
The exposures are different for each policy.

$\lambda(\mathbf{x}_i)$ is the expected number of claims for the duration of policy $i$'s contract.

Normally, $\text{Exposure}_i \not\in \mathbf{x}_i$, and $\lambda(\mathbf{x}_i)$ is the expected rate _per year_, then
$$
Y_i \sim \mathsf{Poisson}(\text{Exposure}_i \times \lambda(\mathbf{x}_i)).
$$
:::

## Poisson probabilities

Since the PMF of the $N \sim \mathsf{Poisson}(\lambda)$ distribution is
$\mathbb{P}(N = k) = \frac{\lambda^k \mathrm{e}^{-\lambda}}{k!}$
then the PMF of $Y_i \sim \mathsf{Poisson}(\lambda(\mathbf{x}_i))$ is

$$
\mathbb{P}(Y_i = y_i) = \frac{ \lambda(\mathbf{x}_i)^{y_i} \, \mathrm{e}^{-\lambda(\mathbf{x}_i)} }{y_i!}
$$

The likelihood of a sample is then
$$
\mathbb{P}(Y_1 = y_1, \dots, Y_n = y_n) = \prod_{i=1}^n \mathbb{P}(Y_i = y_i).
$$

## Log-likelihood

Therefore, the likelihood of $\{ (\mathbf{x}_i, y_i) \}_{i=1, \dots, n}$ is

$$
L = \prod_{i=1}^n \frac{ \lambda(\mathbf{x}_i)^{y_i} \, \mathrm{e}^{-\lambda(\mathbf{x}_i)} }{y_i!}
$$

so the log-likelihood is

$$
\begin{aligned}
\ell
&= \sum_{i=1}^n \log \bigl( \frac{ \lambda(\mathbf{x}_i)^{y_i} \, \mathrm{e}^{-\lambda(\mathbf{x}_i)} }{y_i!} \bigr) \\
&= \sum_{i=1}^n y_i \log \bigl( \lambda(\mathbf{x}_i) \bigr) - \lambda(\mathbf{x}_i) - \log(y_i!) .
\end{aligned}
$$

## Maximising the likelihood

Want to find the best NN $\lambda^*$ such that:
$$
\begin{aligned}
\lambda^* 
&= \arg\max_{\lambda} \sum_{i=1}^n y_i \log \bigl( \lambda(\mathbf{x}_i) \bigr) - \lambda(\mathbf{x}_i) - \log(y_i!) \\
&= \arg\max_{\lambda} \sum_{i=1}^n y_i \log \bigl( \lambda(\mathbf{x}_i) \bigr) - \lambda(\mathbf{x}_i) \\
&= \arg\min_{\lambda} \sum_{i=1}^n \lambda(\mathbf{x}_i) - y_i \log \bigl( \lambda(\mathbf{x}_i)\bigr) \\
&= \arg\min_{\lambda} \frac{1}{n} \sum_{i=1}^n \lambda(\mathbf{x}_i) - y_i \log \bigl( \lambda(\mathbf{x}_i)\bigr) .
\end{aligned}
$$

## Keras' "poisson" loss again

```{python}
#| eval: false
help(poisson)
```

```{python}
#| echo: false
print("""Help on function poisson in module keras.losses:

poisson(y_true, y_pred)
    Computes the Poisson loss between y_true and y_pred.
    
    The Poisson loss is the mean of the elements of the `Tensor`
    `y_pred - y_true * log(y_pred)`.
  
...
""")
```

In other words,
$$
\text{PoissonLoss} = \frac{1}{n} \sum_{i=1}^n \lambda(\mathbf{x}_i) - y_i \log \bigl( \lambda(\mathbf{x}_i) \bigr) .
$$

## Poisson deviance

$$
D = 2 \sum_{i=1}^n y_i \log\bigl( \frac{y_i}{\lambda(\mathbf{x}_i)} \bigr) - \bigl( y_i - \lambda(\mathbf{x}_i) \bigr) .
$$

```{python}
from sklearn.metrics import mean_poisson_deviance
y_true = [0, 2, 1]
y_pred = [0.1, 0.9, 0.8]
mean_poisson_deviance(y_true, y_pred)
```

```{python}
deviance = 0
for y_i, yhat_i in zip(y_true, y_pred):
  firstTerm = y_i * np.log(y_i / yhat_i) if y_i > 0 else 0
  deviance += 2 * (firstTerm - (y_i - yhat_i))
meanDeviance = deviance / len(y_true)
deviance, meanDeviance
```

## Poisson deviance as a loss function

Want to find the best NN $\lambda^*$ such that:
$$
\begin{aligned}
\lambda^* 
&= \arg\min_{\lambda} \, 2 \sum_{i=1}^n y_i \log\bigl( \frac{y_i}{\lambda(\mathbf{x}_i)} \bigr) - \bigl( y_i - \lambda(\mathbf{x}_i) \bigr) \\
&= \arg\min_{\lambda} \sum_{i=1}^n y_i \log( y_i ) - y_i \log\bigl( \lambda(\mathbf{x}_i)  \bigr) - y_i + \lambda(\mathbf{x}_i) \\
&= \arg\min_{\lambda} \sum_{i=1}^n - y_i \log\bigl( \lambda(\mathbf{x}_i) \bigr) + \lambda(\mathbf{x}_i) \\
&= \arg\min_{\lambda} \sum_{i=1}^n \lambda(\mathbf{x}_i) - y_i \log\bigl( \lambda(\mathbf{x}_i) \bigr) .
\end{aligned}
$$

## Sklearn/Keras' `.evaluate`

```{python}
#| echo: false
freq = pd.read_csv("freq_data.csv")

# Remove the column named 'IDpol'.
freq = freq.drop("IDpol", axis=1)

# Convert categorical variables to numeric.
freq = pd.get_dummies(freq, columns=["VehGas", "Area", "VehBrand", "Region"])

freq["ClaimNb"] = np.minimum(freq.ClaimNb, 4)

X = freq.drop("ClaimNb", axis=1)
y = freq["ClaimNb"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2022)
X_train_unsc = X_train
X_test_unsc = X_test

catVars = ['VehGas', 'Area', 'VehBrand', 'Region']
ctsVars = ['Exposure', 'VehPower', 'VehAge', 'DrivAge', 'BonusMalus', 'Density']

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler

ct = ColumnTransformer([
        ('Normalise', StandardScaler(), ctsVars)
    ], remainder='passthrough')

X_train = ct.fit_transform(X_train_unsc)
X_test = ct.transform(X_test_unsc)

X_train = pd.DataFrame(X_train, columns=X_train_unsc.columns)
X_test = pd.DataFrame(X_test, columns=X_test_unsc.columns)
``` 

Given a model:
```{python}
model = tf.keras.models.load_model("french-motor.h5")
```
we can calculate the loss on some set of data:
```{python}
print(model.evaluate(X_train, y_train, verbose=False))
print(model.evaluate(X_test, y_test, verbose=False))
```
This is a wrapper for:

```{python}
print(tf.keras.losses.poisson(y_train, model.predict(X_train).flatten()))
print(tf.keras.losses.poisson(y_test, model.predict(X_test).flatten()))
```

## Poisson loss & Poisson deviance

Poisson losses:

```{python}
model.evaluate(X_train, y_train, verbose=False)
```
```{python}
model.evaluate(X_test, y_test, verbose=False)
```

Poisson deviance:

```{python}
y_pred = model.predict(X_train)
mean_poisson_deviance(y_train, y_pred), mean_poisson_deviance(y_train, y_pred) * len(y_pred)
```

```{python}
y_pred = model.predict(X_test)
mean_poisson_deviance(y_test, y_pred), mean_poisson_deviance(y_test, y_pred) * len(y_pred)
```
# Optimisation {data-background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

## Gradient-based learning 

<div>
  <!-- Source for slider with current value shown: https://stackoverflow.com/a/18936328 -->
  Make a guess: <input type="range" min="1" max="100" value="50" class="slider" id="new_guess" oninput="this.nextElementSibling.value = this.value">
  <output>50</output>
  Show derivatives: <input type="checkbox" id="derivs" pys-onClick="show_derivatives">
  Reveal function: <input type="checkbox" id="reveal" pys-onClick="reveal_function">
</div>
<div id="mpl" style="text-align: center;"></div>
<py-script output="mpl" src="pyscript-demo.py" />

## Gradient descent pitfalls

![Potential problems with gradient descent.](Geron-mls2_0406-blur.png)

::: footer
Source: Aur√©lien G√©ron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figure 4-6 (__redacted__).
:::

## Go over all the training data

<br>

Called _batch gradient descent_.

<br>

```python
for i in range(numEpochs):
  gradient = evaluate_gradient(loss_function, data, weights)
  weights = weights - learningRate * gradient
```

## Pick a random training example

<br>

Called _stochastic gradient descent_.

<br>

```python
for i in range(numEpochs):
  rnd.shuffle(data)
  for example in data:
    gradient = evaluate_gradient(loss_function, example, weights)
    weights = weights - learningRate * gradient
```

## Take a group of training examples

<br>

Called _mini-batch gradient descent_.

<br>

```python
for i in range(numEpochs):
  rnd.shuffle(data)
  for b in range(numBatches):
    batch = data[b*batchSize:(b+1)*batchSize]
    gradient = evaluate_gradient(loss_function, batch, weights)
    weights = weights - learningRate * gradient
```

## Mini-batch gradient descent

::: columns
::: column

Why?

1. Because we have to (data is too big)
2. Because it is faster (lots of quick noisy steps > a few slow super accurate steps)
3. The noise helps us jump out of local minima

:::
::: column

![Example of jumping from local minima.](Geron-mls2_0406-blur.png)

:::
:::

::: footer
Source: Aur√©lien G√©ron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figure 4-6 (__redacted__).
:::

## Learning rates

::: columns
::: column

![The learning rate is too small](Geron-mls2_0404-blur.png)

:::
::: column

![The learning rate is too large](Geron-mls2_0405-blur.png)

:::
:::

::: footer
Source: Aur√©lien G√©ron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figures 4-4 and 4-5 (__redacted__).
:::

## Learning rates #2

![Changing the learning rates for a robot arm.](matt-henderson-learning-rates-animation.mov){width=60%}

::: footer
Source: Matt Henderson (2021), [Twitter post](https://twitter.com/matthen2/status/1520427516997025792)
:::

## Learning rate schedule

![Learning curves for various learning rates Œ∑](Geron-mls2_1108-blur.png)

In training the learning rate may be tweaked manually.

::: footer
Source: Aur√©lien G√©ron (2019), _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_, 2nd Edition, Figure 11-8 (__redacted__).
:::


## We need non-zero derivatives

This is why can't use accuracy as the loss function for classification.

This is why we can have the _dead ReLU_ problem.

<figure>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/KpKog-L9veg?enablejsapi=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</center>
<p></p><figcaption aria-hidden="true">The ‚ÄúExplain Like I‚Äôm 5‚Äù version of softmax/argmax classifiers.</figcaption><p></p>
</figure>

# Classes and objects {background-image="unsw-yellow-shape.png"}

## Make your own types

Often, the built-in types (`int`, `double`, `list`, etc.) aren't enough. 
Need to make a new type of object.

### Example: students

Many students, similar characteristics, but unique values of:

- name,
- zID,
- grades.

Shared way to calculate WAM.

## An empty class

Start off by making the simplest class possible.
```{python}
class Student:
  pass
```

We can create student objects using:

```{python}
don = Student()
zhuge = Student()
```

## Add their names

Let each student object store a name.

```{python}
class Student:
  def __init__(self, name):
    self.name = name
```
```{python}
don = Student("Don Quixote")
zhuge = Student("Zhuge Liang")
```

```{python}
don.name
```

```{python}
zhuge.name
```

::: fragment
::: {.callout-important}
The first parameter for each function inside a class is `self`.
:::
:::

## Add their zIDs and grades

```{python}
#| data-id: student-class
class Student:
  def __init__(self, name, zID, grades):
    self.name = name
    self.zID = zID
    self.grades = grades
```

```{python}
don = Student("Don Quixote", 111222,
    {"ACTL3143": 100, "ACTL5001": 50})
zhuge = Student("Zhuge Liang", 123456,
    {"ACTL3143": 100, "ACTL5001": 100})
```

```{python}
print(don.zID)
zhuge.grades
```

:::{.callout-note}
At this point, `Student` is just POD (plain old data).
:::

## Adding a method

```{python}
#| data-id: student-class
COURSE_CREDITS = {"ACTL3143": 6, "ACTL5001": 12}

class Student:
  def __init__(self, name, zID, grades):
    self.name = name
    self.zID = zID
    self.grades = grades

  def wam(self):
    """
    Calculate the weighted average mark for this student.
    """
    total_credits = 0
    total_grade = 0
    for course, grade in self.grades.items():
      total_credits += COURSE_CREDITS[course]
      total_grade += grade * COURSE_CREDITS[course]
    return total_grade / total_credits
```

## Calling the `wam` method

Now every student object can calculate its own WAM.

```{python}
don = Student("Don Quixote", 111222,
    {"ACTL3143": 100, "ACTL5001": 50})

zhuge = Student("Zhuge Liang", 123456, 
    {"ACTL3143": 100, "ACTL5001": 100})
```

```{python}
don.wam()
```

```{python}
zhuge.wam()
```

::: {.callout-note}
Here, the syntax is `object.method()`.
:::

## Getting help on a method

In Python:
```{python}
help(zhuge.wam)
```

In Jupyter/Colab:
```{python}
?zhuge.wam
```

```{python}
zhuge.wam?
```
## Calling `dir` on an object

```{python}
dir(zhuge)
```

Ignore the `__bla__` things.
These _dunder_ methods are internal/private details.

# Lambda functions {background-image="unsw-yellow-shape.png"}

## Anonymous 'lambda' functions {auto-animate="true"}

Example: how to sort strings by their second letter?

```{python}
names = ["Josephine", "Patrick", "Bert"]
```

If you try `help(sorted)` you'll find the `key` parameter.


```{python}
for name in names:
    print(f"The length of '{name}' is {len(name)}.")
```

```{python}
sorted(names, key=len)
```

## Anonymous 'lambda' functions {auto-animate="true"}

Example: how to sort strings by their second letter?
```{python}
names = ["Josephine", "Patrick", "Bert"]
```

If you try `help(sorted)` you'll find the `key` parameter.

```{python}
def secondLetter(name):
    return name[1]
```

```{python}
for name in names:
    print(f"The second letter of '{name}' is '{secondLetter(name)}'.")
```

```{python}
sorted(names, key=secondLetter)
```

## Anonymous 'lambda' functions {auto-animate="true"}

Example: how to sort strings by their second letter?
```{python}
names = ["Josephine", "Patrick", "Bert"]
```

If you try `help(sorted)` you'll find the `key` parameter.

```{python}
sorted(names, key=lambda name: name[1])
```

::: fragment

::: callout-caution
Don't use `lambda` as a variable name!
You commonly see `lambd` or `lambda_` or `Œª`.
:::

:::

## StoryWall #1 Challenge Solution

<br>

```{python}
def prioritise_attacking_moves(board):

    def movePriority(x):
        move = board.san(x)
        movePriority = 0
        if "#" in move:
            movePriority += 3
        if "+" in move:
            movePriority += 2
        if "x" in move:
            movePriority += 1
        return movePriority
    
    moves = list(board.legal_moves)
    return sorted(moves, key=movePriority, reverse=True)
```

# {data-visibility="uncounted"}

<h2>Glossary</h2>

::: columns
::: column
- accuracy
- batches, batch size
- callbacks
- cross-entropy loss
- early stopping
- gradient-based learning, hill-climbing
:::
::: column
- metrics
- overfitting
- shallow neural network
- stochastic (mini-batch) gradient descent
- validation set
:::
:::

<script defer>
    // Remove the highlight.js class for the 'compile', 'min', 'max'
    // as there's a bug where they are treated like the Python built-in
    // global functions but we only ever see it as methods like
    // 'model.compile()' or 'predictions.max()'
    buggyBuiltIns = ["compile", "min", "max", "round", "sum"];

    document.querySelectorAll('.bu').forEach((elem) => {
        if (buggyBuiltIns.includes(elem.innerHTML)) {
            elem.classList.remove('bu');
        }
    })

    var registerRevealCallbacks = function() {
        Reveal.on('overviewshown', event => {
            document.querySelector(".line.right").hidden = true;
        });
        Reveal.on('overviewhidden', event => {
            document.querySelector(".line.right").hidden = false;
        });
    };
</script>
